{"cells":[{"cell_type":"markdown","metadata":{"id":"H0i9vGFTwG23"},"source":["# MSc Demo Training"]},{"cell_type":"markdown","metadata":{"id":"vHTHJ1iqb79C"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36477,"status":"ok","timestamp":1692347858445,"user":{"displayName":"Mojuba Oladewa","userId":"07848749317453988894"},"user_tz":-60},"id":"qU0ylAkFSUE0","outputId":"d5bf152b-0789-4210-a5da-0672b9de2ef4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1692347858450,"user":{"displayName":"Mojuba Oladewa","userId":"07848749317453988894"},"user_tz":-60},"id":"Im_Jt9HJbSRw","outputId":"c244e3e7-1980-4a09-b663-fa10acb77797"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/DISSERTATION/2_Training\n"]}],"source":["# replace this with the path to your project\n","%cd /content/drive/MyDrive/Colab Notebooks/DISSERTATION/2_Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":789,"status":"ok","timestamp":1692347859211,"user":{"displayName":"Mojuba Oladewa","userId":"07848749317453988894"},"user_tz":-60},"id":"3047TOtfbcPf","outputId":"9af98c05-c77f-462e-f788-b0e9dfeb273f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/DISSERTATION/2_Training\n"]}],"source":["# confirm it works by running this cell and checking the output matched the path in the above cell\n","!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5290,"status":"ok","timestamp":1692347864451,"user":{"displayName":"Mojuba Oladewa","userId":"07848749317453988894"},"user_tz":-60},"id":"7fLSBBJdzmLe","outputId":"30dda884-1081-4abe-ca05-2e70d6b83d34"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/178.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/178.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/953.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m952.3/953.8 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# install the stable baselines 3 library\n","!pip install stable_baselines3 -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSo8Q0bkxcf3"},"outputs":[],"source":["import gymnasium\n","\n","# utils imports\n","import numpy as np\n","import pandas as pd\n","import random\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# environment imports\n","import numpy as np\n","import pandas as pd\n","import random\n","import os\n","import json\n","import sys\n","import pickle\n","import matplotlib.pyplot as plt\n","from matplotlib.patches import Polygon\n","\n","# training imports\n","import torch\n","from stable_baselines3 import PPO  # project 4\n","from stable_baselines3.common.vec_env import DummyVecEnv\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n","\n","# set seed variable\n","seed = 42"]},{"cell_type":"markdown","metadata":{"id":"72_aM8omxfby"},"source":["## Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQ7QbZXdxksE"},"outputs":[],"source":["# calculate profit\n","def calculate_profit(position_size, trade_direction, entry_price, exit_price):\n","\n","    fixed_t_cost = 0.0001  # hopefully we can increase this at some point\n","    size_multiplier = 1.0  # this is a hyperparameter we can play around with\n","    position_size = position_size * size_multiplier\n","\n","    # fixed transaction cost\n","    t_cost = fixed_t_cost * position_size\n","\n","    price_change = (exit_price - entry_price) / entry_price\n","\n","    if trade_direction == 1:\n","        profit = price_change * position_size\n","    elif trade_direction == -1:\n","        profit = -price_change * position_size\n","    else:\n","        return 0, 0\n","\n","    trade_profit = profit - t_cost\n","    marginal_return = trade_profit / (position_size * entry_price)\n","\n","    return trade_profit, marginal_return\n","\n","# get datasets\n","def get_data(pair, window, theta):\n","\n","    train_df = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/DISSERTATION/1_DataTransformation/TransformedData/{theta}/{pair}/Window_{window}/train.parquet.gzip')\n","    val_df = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/DISSERTATION/1_DataTransformation/TransformedData/{theta}/{pair}/Window_{window}/validation.parquet.gzip')\n","    test_df = pd.read_parquet(f'/content/drive/MyDrive/Colab Notebooks/DISSERTATION/1_DataTransformation/TransformedData/{theta}/{pair}/Window_{window}/test.parquet.gzip')\n","\n","    # get ask prices\n","    train_asks = train_df['Ask'].values\n","    val_asks = val_df['Ask'].values\n","    test_asks = test_df['Ask'].values\n","\n","    # get bid prices\n","    train_bids = train_df['Bid'].values\n","    val_bids = val_df['Bid'].values\n","    test_bids = test_df['Bid'].values\n","\n","    # train_df, val_df, test_df = normalize_dataframes(train_df, val_df, test_df)\n","    train_df, val_df, test_df = manual_normalise(train_df, val_df, test_df)\n","\n","    # temp remove to match old approach\n","    train_df = train_df.drop(['Direction', 'Ask', 'Bid', 'Spread'], axis=1)\n","    val_df = val_df.drop(['Direction', 'Ask', 'Bid', 'Spread'], axis=1)\n","    test_df = test_df.drop(['Direction', 'Ask', 'Bid', 'Spread'], axis=1)\n","\n","    if 'JPY' in pair:\n","        train_df[['Start', 'DCC']] = train_df[['Start', 'DCC']] / 100\n","        val_df[['Start', 'DCC']] = val_df[['Start', 'DCC']] / 100\n","        test_df[['Start', 'DCC']] = test_df[['Start', 'DCC']] / 100\n","\n","    # print(train_df.head)\n","    # print(train_df.columns.to_list())\n","\n","    train_data = train_df.values\n","    val_data = val_df.values\n","    test_data = test_df.values\n","\n","    data_dict = {\n","        'train_data': train_data,\n","        'train_asks': train_asks,\n","        'train_bids': train_bids,\n","        'val_data': val_data,\n","        'val_asks': val_asks,\n","        'val_bids': val_bids,\n","        'test_data': test_data,\n","        'test_asks': test_asks,\n","        'test_bids': test_bids\n","    }\n","\n","    print(\"------- Data -------\")\n","    print(f\"Train Shape: {train_data.shape}\")\n","    print(f\"Validation Shape: {val_data.shape}\")\n","    print(f\"Test Shape: {test_data.shape}\")\n","\n","    return data_dict\n","\n","# percentage change\n","def pct_change(old_value, new_value):\n","    change = new_value - old_value\n","    percentage_change = (change / old_value)\n","    return percentage_change\n","\n","# shift by n, new start values are replace by np.nan and end values are discarded\n","def shift(array, shift):\n","    return np.concatenate(([np.nan] * shift, array[:-shift]))\n","\n","# rolling window generator, left over events are discarded\n","def rolling_window(df, window_size, shift):\n","    for i in range(0, len(df) - window_size + 1, shift):\n","        yield df.iloc[i:i+window_size]\n","\n","# take train, validation and test sets and normalise based on training data\n","def normalize_dataframes(train_df, val_df, test_df):\n","    # create a MinMaxScaler object\n","    scaler = MinMaxScaler()\n","\n","    # fit the scaler on the train DataFrame\n","    scaler.fit(train_df)\n","\n","    # normalize each DataFrame using the fitted scaler\n","    train_normalized = pd.DataFrame(scaler.transform(train_df), columns=train_df.columns)\n","    val_normalized = pd.DataFrame(scaler.transform(val_df), columns=val_df.columns)\n","    test_normalized = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n","\n","    return train_normalized, val_normalized, test_normalized\n","\n","def manual_normalise(train_df, val_df, test_df):\n","\n","    DC_start_end = train_df[['Start', 'DCC']]\n","    train_transformed = (train_df - train_df.min()) / (train_df.max() - train_df.min())\n","    train_transformed[['Start', 'DCC']] = DC_start_end\n","\n","    DC_start_end = val_df[['Start', 'DCC']]\n","    val_transformed = (val_df - train_df.min()) / (train_df.max() - train_df.min())\n","    val_transformed[['Start', 'DCC']] = DC_start_end\n","\n","    DC_start_end = test_df[['Start', 'DCC']]\n","    test_transformed = (test_df - train_df.min()) / (train_df.max() - train_df.min())\n","    test_transformed[['Start', 'DCC']] = DC_start_end\n","\n","    return train_transformed, val_transformed, test_transformed\n","\n","\n","# trend class\n","class Trend(object):\n","    def __init__(self, direction, DC_start, DCC, OS_end, DC_start_index, DCC_index, OS_end_index):\n","        self.direction, self.DC_start, self.DCC, self.OS_end = direction, DC_start, DCC, OS_end\n","        self.DC_start_index, self.DCC_index, self.OS_end_index = DC_start_index, DCC_index, OS_end_index\n","\n","        self.data_dict = {\n","                'Direction': self.direction,\n","                'Start': round(self.DC_start, 6),\n","                'DCC': round(self.DCC, 6),\n","                'End': round(self.OS_end, 6),\n","                'Start Index': round(self.DC_start_index, 6),\n","                'DCC Index': round(self.DCC_index, 6),\n","                'End Index': round(self.OS_end_index, 6),\n","            }\n","\n","    def __str__(self):\n","        return str(self.data_dict)"]},{"cell_type":"markdown","metadata":{"id":"sVMk8ob6xVxQ"},"source":["## Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJfBEeQ6wDPD"},"outputs":[],"source":["with open('/content/drive/MyDrive/Colab Notebooks/DISSERTATION/params.json', 'r') as f:\n","    params = json.load(f)\n","\n","class DirectionalChangeEnv(gymnasium.Env):\n","    def __init__(self, env_config):\n","\n","        # get data from config\n","        data = env_config['data']\n","        asks = env_config['asks']\n","        bids = env_config['bids']\n","\n","        self.full_data = data\n","        self.full_asks = asks\n","        self.full_bids = bids\n","\n","        # init state params\n","        self.context_length = int(params['training']['context_length'])\n","        self.lag = int(params['training']['lag'])\n","        try:\n","            self.start_index = random.randint(0, len(self.full_data) - (self.context_length + 1))\n","        except:\n","            self.start_index = 0\n","        self.end_index = self.start_index + self.context_length\n","\n","        # init data\n","        self.data = self.full_data[self.start_index: self.end_index]\n","        self.asks = self.full_asks[self.start_index: self.end_index]\n","        self.bids = self.full_bids[self.start_index: self.end_index]\n","\n","        # init state\n","        self.i = self.lag - 1\n","        self.state = self.data[0:self.i + 1]  # (lag, 32)\n","        self.ask_price = asks[self.i]  # (1)\n","        self.bid_price = bids[self.i]  # (1)\n","\n","        # set action and observation space\n","        self.action_space = gymnasium.spaces.Discrete(2)  # buy, sell\n","        self.observation_space = gymnasium.spaces.Box(0, 2, shape=self.state.shape)  # DC start, DC end for last 5 timesteps\n","\n","        # init simulation params\n","        self.n_prices = len(self.data) - self.lag\n","        self.balance = 100\n","        self.entry_price = None\n","        self.position_size = None\n","        self.in_position = 0  # -1 for short, 0 for no, 1 for long\n","        self.trading_log = []\n","\n","    def step(self, action):\n","\n","        self.i += 1\n","        self.n_prices -= 1\n","        self.state = self.data[self.i - (self.lag-1) : self.i + 1]\n","        self.ask_price = self.asks[self.i]\n","        self.bid_price = self.bids[self.i]\n","        self.mid_price = (self.ask_price + self.bid_price) / 2\n","\n","        # reward function\n","        if self.in_position == 0:\n","            if action == 0:  #  buy\n","                self.entry_price = self.mid_price  # long at ask price\n","                self.position_size = self.balance\n","                self.in_position = 1\n","                reward = 0\n","            elif action == 1:  # sell\n","                self.entry_price = self.mid_price  # short at bid price\n","                self.position_size = self.balance\n","                self.in_position = -1\n","                reward = 0\n","\n","        elif self.in_position == -1:\n","            if action == 0:  #  buy\n","                profit, _ = calculate_profit(self.position_size, self.in_position,\n","                                          self.entry_price, self.mid_price)  # exit short position at ask price\n","                self.trading_log.append({'Trade Index': self.i,\n","                                         'Position Size': self.position_size,\n","                                         'Trade Type': 'Short',\n","                                         'Entry Price': self.entry_price,\n","                                         'Exit Price': self.mid_price,\n","                                         'Profit': profit})\n","                reward = profit\n","                self.balance += profit\n","                self.in_position = 0\n","                self.position_size = None\n","                self.entry_price = None\n","            elif action == 1:  # sell\n","                reward = 0\n","\n","        elif self.in_position == 1:\n","            if action == 0:  #  buy\n","                reward = 0\n","            elif action == 1:  # sell\n","                profit, _ = calculate_profit(self.position_size, self.in_position,\n","                                          self.entry_price, self.mid_price)  # exit long position as bid price\n","                self.trading_log.append({'Trade Index': self.i,\n","                                         'Position Size': self.position_size,\n","                                         'Trade Type': 'Long',\n","                                         'Entry Price': self.entry_price,\n","                                         'Exit Price': self.mid_price,\n","                                         'Profit': profit})\n","                reward = profit\n","                self.balance += profit\n","                self.in_position = 0\n","                self.position_size = None\n","                self.entry_price = None\n","\n","        if self.n_prices <= 0 or self.balance <= 0:\n","            done = True\n","            if self.in_position != 0:\n","\n","                if self.in_position == -1:\n","                    trade_type = 'Short'\n","                    exit_price = self.mid_price\n","                elif self.in_position == 1:\n","                    trade_type = 'Long'\n","                    exit_price = self.mid_price\n","\n","                profit, _ = calculate_profit(self.position_size, self.in_position,\n","                                            self.entry_price, exit_price)\n","                reward = profit\n","\n","                self.trading_log.append({'Trade Index': self.i,\n","                                         'Position Size': self.position_size,\n","                                         'Trade Type': trade_type,\n","                                         'Entry Price': self.entry_price,\n","                                         'Exit Price': exit_price,\n","                                         'Profit': profit})\n","                self.balance += profit\n","                self.in_position = 0\n","        else:\n","            done = False\n","\n","        info = {'balance': self.balance,\n","                'trading_log': self.trading_log}\n","\n","        return self.state, reward, done, False, info\n","\n","    def reset(self, seed=seed, options=None):\n","\n","        # generate new training set\n","        try:\n","            self.start_index = random.randint(0, len(self.full_data) - (self.context_length + 1))\n","        except:\n","            self.start_index = 0\n","        self.end_index = self.start_index + self.context_length\n","        self.data = self.full_data[self.start_index: self.end_index]\n","        self.asks = self.full_asks[self.start_index: self.end_index]\n","        self.bids = self.full_bids[self.start_index: self.end_index]\n","\n","        # reset episode variables\n","        self.i = self.lag - 1\n","        self.state = self.data[0:self.i + 1]\n","        self.ask_price = self.asks[self.i]\n","        self.bid_price = self.bids[self.i]\n","        self.n_prices = len(self.data) - self.lag\n","        self.balance = 100\n","        self.entry_price = None\n","        self.position_size = None\n","        self.in_position = 0  # -1 for short, 0 for no, 1 for long\n","        self.trading_log = []\n","\n","        return self.state, {}\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IkU8xImIz1gk"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOkUzL8qO49-"},"outputs":[],"source":["from stable_baselines3 import PPO, A2C, DQN, TD3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncrVNzamz5BL"},"outputs":[],"source":["class ModelTrainer(object):\n","    \"\"\"class to run training of model\"\"\"\n","    def __init__(self, theta, model_name):\n","\n","        self.theta = theta\n","        self.model_name = model_name\n","\n","        model_obj_dict = {\"PPO\": PPO, \"A2C\": A2C, \"DQN\": DQN, \"TD3\": TD3}\n","\n","        self.model_obj = model_obj_dict[model_name]\n","\n","        # get data\n","        data_dict = get_data(pair, window, theta)\n","        train_data = data_dict['train_data']\n","        train_asks = data_dict['train_asks']\n","        train_bids = data_dict['train_bids']\n","        val_data = data_dict['val_data']\n","        val_asks = data_dict['val_asks']\n","        val_bids = data_dict['val_bids']\n","\n","        # configure training parameters\n","        env_config = {\n","                'data': train_data,\n","                'asks': train_asks,\n","                'bids': train_bids\n","            }\n","\n","        # configure algorithm\n","        log_path = f\"./Logs/{model_name}/{self.theta}/{pair}/Window_{window}\"\n","        env = DirectionalChangeEnv(env_config)\n","        self.model = self.model_obj('MlpPolicy', env, verbose=1, tensorboard_log=log_path)\n","\n","    def save_checkpoint(self):\n","        # save model\n","        model_folder = f'./Models/{self.model_name}/{self.theta}/{pair}/'\n","        self.model.save(model_folder + f'{self.model_name}_Window_{window}')\n","        print('model saved')\n","\n","    def train(self):\n","        self.model.learn(total_timesteps=200000)  # change timesteps to e.g. 10000 for a shorted training process to check it's working\n"]},{"cell_type":"markdown","metadata":{"id":"P-f49zmXdIW8"},"source":["## Run Experiment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":466871,"status":"ok","timestamp":1692351305711,"user":{"displayName":"Mojuba Oladewa","userId":"07848749317453988894"},"user_tz":-60},"id":"VSXdp_h-dH0P","outputId":"4bbfe3d1-3504-43c6-dcfb-571679326f38"},"outputs":[{"output_type":"stream","name":"stdout","text":["------- Data -------\n","Train Shape: (2097, 30)\n","Validation Shape: (1064, 30)\n","Test Shape: (531, 30)\n","Using cpu device\n","Wrapping the env with a `Monitor` wrapper\n","Wrapping the env in a DummyVecEnv.\n","Logging to ./Logs/DQN/0.00023/USDCAD/Window_18/DQN_3\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.37    |\n","|    exploration_rate | 0.811    |\n","| time/               |          |\n","|    episodes         | 4        |\n","|    fps              | 370      |\n","|    time_elapsed     | 10       |\n","|    total_timesteps  | 3980     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.33    |\n","|    exploration_rate | 0.622    |\n","| time/               |          |\n","|    episodes         | 8        |\n","|    fps              | 413      |\n","|    time_elapsed     | 19       |\n","|    total_timesteps  | 7960     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.46    |\n","|    exploration_rate | 0.433    |\n","| time/               |          |\n","|    episodes         | 12       |\n","|    fps              | 396      |\n","|    time_elapsed     | 30       |\n","|    total_timesteps  | 11940    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.45    |\n","|    exploration_rate | 0.244    |\n","| time/               |          |\n","|    episodes         | 16       |\n","|    fps              | 387      |\n","|    time_elapsed     | 41       |\n","|    total_timesteps  | 15920    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.5     |\n","|    exploration_rate | 0.0547   |\n","| time/               |          |\n","|    episodes         | 20       |\n","|    fps              | 393      |\n","|    time_elapsed     | 50       |\n","|    total_timesteps  | 19900    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.33    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 24       |\n","|    fps              | 392      |\n","|    time_elapsed     | 60       |\n","|    total_timesteps  | 23880    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.32    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 28       |\n","|    fps              | 387      |\n","|    time_elapsed     | 71       |\n","|    total_timesteps  | 27860    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.29    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 32       |\n","|    fps              | 383      |\n","|    time_elapsed     | 82       |\n","|    total_timesteps  | 31840    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.31    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 36       |\n","|    fps              | 390      |\n","|    time_elapsed     | 91       |\n","|    total_timesteps  | 35820    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.35    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 40       |\n","|    fps              | 388      |\n","|    time_elapsed     | 102      |\n","|    total_timesteps  | 39800    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.37    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 44       |\n","|    fps              | 385      |\n","|    time_elapsed     | 113      |\n","|    total_timesteps  | 43780    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.4     |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 48       |\n","|    fps              | 390      |\n","|    time_elapsed     | 122      |\n","|    total_timesteps  | 47760    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.35    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 52       |\n","|    fps              | 389      |\n","|    time_elapsed     | 132      |\n","|    total_timesteps  | 51740    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00055  |\n","|    n_updates        | 434      |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.27    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 56       |\n","|    fps              | 389      |\n","|    time_elapsed     | 143      |\n","|    total_timesteps  | 55720    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000234 |\n","|    n_updates        | 1429     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.22    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 60       |\n","|    fps              | 386      |\n","|    time_elapsed     | 154      |\n","|    total_timesteps  | 59700    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000253 |\n","|    n_updates        | 2424     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.18    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 64       |\n","|    fps              | 389      |\n","|    time_elapsed     | 163      |\n","|    total_timesteps  | 63680    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000128 |\n","|    n_updates        | 3419     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.15    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 68       |\n","|    fps              | 389      |\n","|    time_elapsed     | 173      |\n","|    total_timesteps  | 67660    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000247 |\n","|    n_updates        | 4414     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.12    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 72       |\n","|    fps              | 391      |\n","|    time_elapsed     | 183      |\n","|    total_timesteps  | 71640    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00287  |\n","|    n_updates        | 5409     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.09    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 76       |\n","|    fps              | 394      |\n","|    time_elapsed     | 191      |\n","|    total_timesteps  | 75620    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000162 |\n","|    n_updates        | 6404     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.07    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 80       |\n","|    fps              | 395      |\n","|    time_elapsed     | 201      |\n","|    total_timesteps  | 79600    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 7.94e-05 |\n","|    n_updates        | 7399     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.07    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 84       |\n","|    fps              | 394      |\n","|    time_elapsed     | 211      |\n","|    total_timesteps  | 83580    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000686 |\n","|    n_updates        | 8394     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.05    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 88       |\n","|    fps              | 394      |\n","|    time_elapsed     | 222      |\n","|    total_timesteps  | 87560    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 8.17e-05 |\n","|    n_updates        | 9389     |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.04    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 92       |\n","|    fps              | 392      |\n","|    time_elapsed     | 233      |\n","|    total_timesteps  | 91540    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000148 |\n","|    n_updates        | 10384    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -3.01    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 96       |\n","|    fps              | 396      |\n","|    time_elapsed     | 240      |\n","|    total_timesteps  | 95520    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 8.69e-05 |\n","|    n_updates        | 11379    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.99    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 100      |\n","|    fps              | 397      |\n","|    time_elapsed     | 250      |\n","|    total_timesteps  | 99500    |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000213 |\n","|    n_updates        | 12374    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.95    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 104      |\n","|    fps              | 398      |\n","|    time_elapsed     | 259      |\n","|    total_timesteps  | 103480   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 7.74e-05 |\n","|    n_updates        | 13369    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.93    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 108      |\n","|    fps              | 401      |\n","|    time_elapsed     | 267      |\n","|    total_timesteps  | 107460   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000241 |\n","|    n_updates        | 14364    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.9     |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 112      |\n","|    fps              | 402      |\n","|    time_elapsed     | 276      |\n","|    total_timesteps  | 111440   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000166 |\n","|    n_updates        | 15359    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.88    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 116      |\n","|    fps              | 405      |\n","|    time_elapsed     | 284      |\n","|    total_timesteps  | 115420   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000253 |\n","|    n_updates        | 16354    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.85    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 120      |\n","|    fps              | 406      |\n","|    time_elapsed     | 293      |\n","|    total_timesteps  | 119400   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 8.83e-05 |\n","|    n_updates        | 17349    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.86    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 124      |\n","|    fps              | 408      |\n","|    time_elapsed     | 302      |\n","|    total_timesteps  | 123380   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 9.45e-05 |\n","|    n_updates        | 18344    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.83    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 128      |\n","|    fps              | 410      |\n","|    time_elapsed     | 310      |\n","|    total_timesteps  | 127360   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000442 |\n","|    n_updates        | 19339    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.79    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 132      |\n","|    fps              | 410      |\n","|    time_elapsed     | 319      |\n","|    total_timesteps  | 131340   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 5.12e-05 |\n","|    n_updates        | 20334    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.75    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 136      |\n","|    fps              | 413      |\n","|    time_elapsed     | 327      |\n","|    total_timesteps  | 135320   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00287  |\n","|    n_updates        | 21329    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.7     |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 140      |\n","|    fps              | 414      |\n","|    time_elapsed     | 336      |\n","|    total_timesteps  | 139300   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 7.48e-05 |\n","|    n_updates        | 22324    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.65    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 144      |\n","|    fps              | 416      |\n","|    time_elapsed     | 344      |\n","|    total_timesteps  | 143280   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 2.27e-05 |\n","|    n_updates        | 23319    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.61    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 148      |\n","|    fps              | 417      |\n","|    time_elapsed     | 352      |\n","|    total_timesteps  | 147260   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000237 |\n","|    n_updates        | 24314    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.61    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 152      |\n","|    fps              | 415      |\n","|    time_elapsed     | 363      |\n","|    total_timesteps  | 151240   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 8.58e-05 |\n","|    n_updates        | 25309    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.61    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 156      |\n","|    fps              | 418      |\n","|    time_elapsed     | 370      |\n","|    total_timesteps  | 155220   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000173 |\n","|    n_updates        | 26304    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.63    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 160      |\n","|    fps              | 419      |\n","|    time_elapsed     | 379      |\n","|    total_timesteps  | 159200   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000454 |\n","|    n_updates        | 27299    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.62    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 164      |\n","|    fps              | 420      |\n","|    time_elapsed     | 387      |\n","|    total_timesteps  | 163180   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000176 |\n","|    n_updates        | 28294    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.62    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 168      |\n","|    fps              | 421      |\n","|    time_elapsed     | 396      |\n","|    total_timesteps  | 167160   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000393 |\n","|    n_updates        | 29289    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.62    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 172      |\n","|    fps              | 422      |\n","|    time_elapsed     | 405      |\n","|    total_timesteps  | 171140   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 5.21e-05 |\n","|    n_updates        | 30284    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.61    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 176      |\n","|    fps              | 424      |\n","|    time_elapsed     | 412      |\n","|    total_timesteps  | 175120   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000281 |\n","|    n_updates        | 31279    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.62    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 180      |\n","|    fps              | 424      |\n","|    time_elapsed     | 422      |\n","|    total_timesteps  | 179100   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000105 |\n","|    n_updates        | 32274    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.6     |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 184      |\n","|    fps              | 426      |\n","|    time_elapsed     | 429      |\n","|    total_timesteps  | 183080   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00111  |\n","|    n_updates        | 33269    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.59    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 188      |\n","|    fps              | 426      |\n","|    time_elapsed     | 438      |\n","|    total_timesteps  | 187060   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.00177  |\n","|    n_updates        | 34264    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.58    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 192      |\n","|    fps              | 428      |\n","|    time_elapsed     | 445      |\n","|    total_timesteps  | 191040   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 4.59e-05 |\n","|    n_updates        | 35259    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.57    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 196      |\n","|    fps              | 428      |\n","|    time_elapsed     | 454      |\n","|    total_timesteps  | 195020   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000342 |\n","|    n_updates        | 36254    |\n","----------------------------------\n","----------------------------------\n","| rollout/            |          |\n","|    ep_len_mean      | 995      |\n","|    ep_rew_mean      | -2.57    |\n","|    exploration_rate | 0.05     |\n","| time/               |          |\n","|    episodes         | 200      |\n","|    fps              | 429      |\n","|    time_elapsed     | 463      |\n","|    total_timesteps  | 199000   |\n","| train/              |          |\n","|    learning_rate    | 0.0001   |\n","|    loss             | 0.000152 |\n","|    n_updates        | 37249    |\n","----------------------------------\n","model saved\n"]}],"source":["# set seeds - this is to ensure reproducibility\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","# set script variables\n","pair = str('USDCAD')  # run for all pairs: AUDUSD, EURGBP, EURUSD and USDCAD\n","window = int(18) # run for all windows (see e.g. /1_DataTransformation/TransformedData/0.00013/AUDUSD/ for list of windows)\n","theta = float(0.00023)  # run for all thresholds: 0.00013, 0.00017, 0.00023\n","model_name = 'DQN'  # PPO, A2C, DQN\n","\n","# create experiment\n","trainer = ModelTrainer(theta, model_name)\n","\n","# train the model\n","trainer.train()\n","\n","# save model\n","trainer.save_checkpoint()"]}],"metadata":{"colab":{"collapsed_sections":["vHTHJ1iqb79C","72_aM8omxfby","sVMk8ob6xVxQ","IkU8xImIz1gk"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}